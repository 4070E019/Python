
21個項目玩轉深度學習——基於TensorFlow的實踐詳解  

作者：何之源 出版時間：2018-03


```
第1章  MNIST機器學習入門	1
1.1  MNIST資料集	2
1.1.1  簡介	2
1.1.2  實驗：將MNIST資料集保存為圖片	5
1.1.3  圖像標籤的獨熱(one-hot)表示	6
1.2  利用TensorFlow識別MNIST	8
1.2.1  Softmax回歸	8
1.2.2  兩層卷積網路分類	14
1.3  總結	18

第2章  CIFAR-10與ImageNet圖像識別	19
2.1  CIFAR-10資料集	20
2.1.1  CIFAR-10簡介	20
2.1.2  下載CIFAR-10數據	21
2.1.3  TensorFlow的資料讀取機制	23
2.1.4  實驗：將CIFAR-10資料集保存為圖片形式	30
2.2  利用TensorFlow訓練CIFAR-10識別模型	34
2.2.1  資料增強（Data Augmentation）	34
2.2.2  CIFAR-10識別模型	36
2.2.3  訓練模型	39
2.2.4  在TensorFlow中查看訓練進度	39
2.2.5  測試模型效果	42
2.3  ImageNet圖像識別模型	44
2.3.1  ImageNet資料集簡介	44
2.3.2  歷代ImageNet圖像識別模型	45
2.4  總結	49

第3章  打造自己的圖像識別模型	50
3.1  微調（Fine-tune）的原理	51
3.2  數據準備	52
3.3  使用TensorFlow Slim微調模型	56
3.3.1  下載TensorFlow Slim的原始程式碼	56
3.3.2  定義新的datasets檔	57
3.3.3  準備訓練資料夾	59
3.3.4  開始訓練	60
3.3.5  訓練程式列為	62
3.3.6  驗證模型正確率	63
3.3.7  TensorBoard視覺化與超參數選擇	64
3.3.8  匯出模型並對單張圖片進行識別	65
3.4  總結	69

第4章  Deep Dream模型	70
4.1  Deep Dream的技術原理	71
4.2  TensorFlow中的Deep Dream模型實踐	73
4.2.1  導入Inception模型	73
4.2.2  生成原始的Deep Dream圖像	76
4.2.3  生成更大尺寸的Deep Dream圖像	78
4.2.4  生成更高品質的Deep Dream圖像	82
4.2.5  最終的Deep Dream模型	87
4.3  總結	90


第5章  深度學習中的目標檢測	91
5.1  深度學習中目標檢測的原理	92
5.1.1  R-CNN的原理	92
5.1.2  SPPNet的原理	94
5.1.3  Fast R-CNN的原理	97
5.1.4  Faster R-CNN的原理	98
5.2  TensorFlow Object Detection API	101
5.2.1  安裝TensorFlow Object Detection API	101
5.2.2  執行已經訓練好的模型	103
5.2.3  訓練新的模型	109
5.2.4  匯出模型並預測單張圖片	113
5.3  總結	114

第6章  人臉檢測和人臉識別	115
6.1  MTCNN的原理	116
6.2  使用深度卷積網路提取特徵	121
6.2.1  三元組損失（Triplet Loss）的定義	123
6.2.2  中心損失（Center Loss）的定義	123
6.3  使用特徵設計應用	125
6.4  在TensorFlow中實現人臉識別	126
6.4.1  專案環境設置	126
6.4.2  LFW人臉資料庫	127
6.4.3  LFW資料庫上的人臉檢測和對齊	128
6.4.4  使用已有模型驗證LFW資料庫準確率	129
6.4.5  在自己的資料上使用已有模型	130
6.4.6  重新訓練新模型	133
6.4.7  三元組損失和中心損失的定義	138
6.5  總結	140

第7章  圖像風格遷移	141
7.1  圖像風格遷移的原理	142
7.1.1  原始圖像風格遷移的原理	142
7.1.2  快速圖像風格遷移的原理	148
7.2  在TensorFlow中實現快速風格遷移	149
7.2.1  使用預訓練模型	150
7.2.2  訓練自己的模型	153
7.2.3  在TensorBoard中監控訓練情況	154
7.2.4  項目實現細節	157
7.3  總結	162

第8章  GAN和DCGAN入門	163
8.1  GAN的原理	164
8.2  DCGAN的原理	166
8.3  在TensorFlow中用DCGAN生成圖像	169
8.3.1  生成MNIST圖像	170
8.3.2  使用自己的資料集訓練	171
8.3.3  程式結構分析：如何將圖像讀入模型	173
8.3.4  程式結構分析：視覺化方法	177
8.4  總結	180

第9章  pix2pix模型與自動上色技術	181
9.1  cGAN的原理	182
9.2  pix2pix模型的原理	184
9.3  TensorFlow中的pix2pix模型	187
9.3.1  執行已有的資料集	187
9.3.2  創建自己的資料集	191
9.4  使用TensorFlow為灰度圖像自動上色	194
9.4.1  為食物圖片上色	194
9.4.2  為動漫圖片進行上色	196
9.5  總結	198

第10章  超解析度：如何讓圖像變得更清晰	199
10.1  數據預處理與訓練	200
10.1.1  去除錯誤圖片	200
10.1.2  將圖像裁剪到統一大小	202
10.1.3  為代碼添加新的操作	202
10.2  總結	209

第11章  CycleGAN與非配對圖像轉換	210
11.1  CycleGAN的原理	211
11.2  在TensorFlow中用訓練CycleGAN模型	213
11.2.1  下載資料集並訓練	213
11.2.2  使用自己的資料進行訓練	217
11.3  程式結構分析	220
11.4  總結	224

第12章  RNN基本結構與Char RNN文本生成	225
12.1  RNN的原理	226
12.1.1  經典RNN的結構	226
12.1.2  N VS 1 RNN的結構	229
12.1.3  1 VS N RNN的結構	230
12.2  LSTM的原理	231
12.3  Char RNN的原理	235
12.4  TensorFlow中的RNN實現方式	237
12.4.1  實現RNN的基本單元：RNNCell	238
12.4.2  對RNN進行堆疊：MultiRNNCell	239
12.4.3  注意點：BasicRNNCell和BasicLSTMCell的output	240
12.4.4  使用tf.nn.dynamic_rnn展開時間維度	241
12.5  使用TensorFlow實現Char RNN	242
12.5.1  定義輸入資料	243
12.5.2  定義多層LSTM模型	244
12.5.3  定義損失	245
12.5.4  訓練模型與生成文字	246
12.5.5  更多參數說明	250
12.5.6  運行自己的資料	250
12.6  總結	251

第13章  序列分類問題詳解	252
13.1  N VS 1的RNN結構	253
13.2  數列分類問題與資料生成	254
13.3  在TensorFlow中定義RNN分類模型	258
13.3.1  定義模型前的準備工作	258
13.3.2  定義RNN分類模型	259
13.3.3  定義損失並進行訓練	261
13.4  模型的推廣	262
13.5  總結	263

第14章  詞的向量表示：word2vec與詞嵌入	264
14.1  為什麼需要做詞嵌入	265
14.2  詞嵌入的原理	266
14.2.1  CBOW實現詞嵌入的原理	266
14.2.2  Skip-Gram實現詞嵌入的原理	269
14.3  在TensorFlow中實現詞嵌入	270
14.3.1  下載資料集	270
14.3.2  製作詞表	272
14.3.3  生成每步的訓練樣本	274
14.3.4  定義模型	276
14.3.5  執行訓練	279
14.3.6  視覺化	281
14.4  與第12章的對比	284
14.5  總結	285

第15章  在TensorFlow中進行時間序列預測	286
15.1  時間序列問題的一般形式	287
15.2  用TFTS讀入時間序列資料	287
15.2.1  從Numpy陣列中讀入時間序列資料	288
15.2.2  從CSV檔中讀入時間序列資料	291
15.3  使用AR模型預測時間序列	293
15.3.1  AR模型的訓練	293
15.3.2  AR模型的驗證和預測	295
15.4  使用LSTM模型預測時間序列	297
15.4.1  LSTM模型中的單變數時間序列預測	297
15.4.2  LSTM模型中的多變數時間序列預測	299
15.5  總結	301

第16章  神經網路機器翻譯技術	302
16.1  Encoder-Decoder模型的原理	303
16.2  注意力機制（Attention）	305
16.3  使用TensorFlow NMT搭建神經網路翻譯引擎	309
16.3.1  示例：將越南語翻譯為英語	309
16.3.2  構建中英翻譯引擎	313
16.4  TensorFlow NMT源碼簡介	317
16.5  總結	319

第17章  看圖說話：將圖像轉換為文字	320
17.1  Image Caption技術綜述	321
17.1.1  從Encoder-Decoder結構談起	321
17.1.2  將Encoder-Decoder應用到Image Caption任務上	322
17.1.3  對Encoder-Decoder的改進1：加入Attention機制	323
17.1.4  對Encoder-Decoder的改進2：加入高層語義	325
17.2  在TensorFlow中實現Image Caption	327
17.2.1  下載代碼	327
17.2.2  環境準備	328
17.2.2  編譯和數據準備	328
17.2.3  訓練和驗證	330
17.2.4  測試單張圖片	331
17.3  總結	332

第18章  強化學習入門之Q	333
18.1  強化學習中的幾個重要概念	334
18.2  Q Learning的原理與實驗	336
18.2.1  環境定義	336
18.2.2  Q函數	338
18.2.3  Q函數的學習策略	339
18.2.4  ?-greedy策略	341
18.2.5  簡單的Q Learning示例	341
18.2.6  更複雜的情況	342
18.3  總結	343

第19章  強化學習入門之SARSA演算法	344
19.1  SARSA 演算法的原理	345
19.1.1  通過與Q Learning對比學習SARSA演算法	345
19.1.2  off-policy與on-policy	346
19.2  SARSA 演算法的實現	347
19.3  總結	348

第20章  深度強化學習：Deep Q Learning	349
20.1  DQN演算法的原理	350
20.1.1  問題簡介	350
20.1.2  Deep Q Network	351
20.1.3  訓練方法	352
20.2  在TensorFlow中運行DQN演算法	353
20.2.1  安裝依賴庫	353
20.2.2  訓練	355
20.2.3  測試	356
20.3  在TensorFlow中DQN演算法的實現分析	357
20.4  總結	360

第21章  策略梯度（Policy Gradient）演算法	361
21.1  策略梯度（Policy Gradient）演算法的原理	362
21.1.1  Cartpole遊戲	362
21.1.2  策略網路（Policy Network）	363
21.1.3  訓練策略網路	364
21.2  在TensorFlow中實現策略梯度 演算法	365
21.2.1  初始化	365
21.2.2  定義策略網路	366
21.2.3  訓練	367
21.3  總結	371

```
