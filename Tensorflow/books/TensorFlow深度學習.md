# TensorFlow深度學習
```
2018年3月

```


```
第 1 章 深度學習入門 1
1．1 機器學習簡介 1
1．1．1 監督學習 2
1．1．2 無監督學習 2
1．1．3 強化學習 3
1．2 深度學習定義 3
1．2．1 人腦的工作機制 3
1．2．2 深度學習歷史 4
1．2．3 應用領域 5
1．3 神經網路 5
1．3．1 生物神經元 5
1．3．2 人工神經元 6
1．4 人工神經網路的學習方式 8
1．4．1 反向傳播演算法 8
1．4．2 權重優化 8
1．4．3 隨機梯度下降法 9
1．5 神經網路架構 10
1．5．1 多層感知器 10
1．5．2 DNN架構 11
1．5．3 卷積神經網路 12
1．5．4 受限玻爾茲曼機 12
1．6 自編碼器 13
1．7 迴圈神經網路 14
1．8 幾種深度學習框架對比 14
1．9 小結 16

2章 TensorFlow初探 17
2．1 總覽 17
2．1．1 TensorFlow 1．x版本特性 18
2．1．2 使用上的改進 18
2．1．3 TensorFlow安裝與入門 19
2．2 在Linux上安裝TensorFlow 19
2．3 為TensorFlow啟用NVIDIA GPU 20
2．3．1 * 1步：安裝NVIDIA CUDA 20
2．3．2 * 2步：安裝NVIDIA cuDNN v5．1+ 21
2．3．3 第3步：確定GPU卡的CUDA計算能力為3．0+ 22
2．3．4 第4步：安裝libcupti-dev庫 22
2．3．5 第5步：安裝Python（或Python3） 22
2．3．6 第6步：安裝並升級PIP（或PIP3） 22
2．3．7 第7步：安裝TensorFlow 23
2．4 如何安裝TensorFlow 23
2．4．1 直接使用pip安裝 23
2．4．2 使用virtualenv安裝 24
2．4．3 從原始程式碼安裝 26
2．5 在Windows上安裝TensorFlow 27
2．5．1 在虛擬機器上安裝TensorFlow 27
2．5．2 直接安裝到Windows 27
2．6 測試安裝是否成功 28
2．7 計算圖 28
2．8 為何採用計算圖 29
2．9 程式設計模型 30
2．10 資料模型 33
2．10．1 階 33
2．10．2 形狀 33
2．10．3 資料類型 34
2．10．4 變數 36
2．10．5 取回 37
2．10．6 注入 38
2．11 TensorBoard 38
2．12 實現一個單輸入神經元 39
2．13 單輸入神經元原始程式碼 43
2．14 遷移到TensorFlow 1．x版本 43
2．14．1 如何用腳本升級 44
2．14．2 局限 47
2．14．3 手動升級代碼 47
2．14．4 變數 47
2．14．5 匯總函數 47
2．14．6 簡化的數學操作 48
2．14．7 其他事項 49
2．15 小結 49

第3章 用TensorFlow構建前饋神經網路 51
3．1 前饋神經網路介紹 51
3．1．1 前饋和反向傳播 52
3．1．2 權重和偏差 53
3．1．3 傳遞函數 53
3．2 手寫數字分類 54
3．3 探究MNIST資料集 55
3．4 Softmax分類器 57
3．5 TensorFlow模型的保存和還原 63
3．5．1 保存模型 63
3．5．2 還原模型 63
3．5．3 Softmax原始程式碼 65
3．5．4 Softmax啟動器原始程式碼 66
3．6 實現一個五層神經網路 67
3．6．1 視覺化 69
3．6．2 五層神經網路原始程式碼 70
3．7 ReLU分類器 72
3．8 視覺化 73
3．9 Dropout優化 76
3．10 視覺化 78
3．11 小結 80

第4章 TensorFlow與卷積神經網路 82
4．1 CNN簡介 82
4．2 CNN架構 84
4．3 構建你的* 一個CNN 86
4．4 CNN表情識別 95
4．4．1 表情分類器原始程式碼 104
4．4．2 使用自己的圖像測試模型 107
4．4．3 原始程式碼 109
4．5 小結 111

第5章 優化TensorFlow自編碼器 112
5．1 自編碼器簡介 112
5．2 實現一個自編碼器 113
5．3 增強自編碼器的魯棒性 119
5．4 構建去噪自編碼器 120
5．5 卷積自編碼器 127
5．5．1 編碼器 127
5．5．2 解碼器 128
5．5．3 卷積自編碼器原始程式碼 134
5．6 小結 138

第6章 迴圈神經網路 139
6．1 RNN的基本概念 139
6．2 RNN的工作機制 140
6．3 RNN的展開 140
6．4 梯度消失問題 141
6．5 LSTM網路 142
6．6 RNN圖像分類器 143
6．7 雙向RNN 149
6．8 文本預測 155
6．8．1 資料集 156
6．8．2 困惑度 156
6．8．3 PTB模型 156
6．8．4 運行常式 157
6．9 小結 158

第7章 GPU計算 160
7．1 GPGPU計算 160
7．2 GPGPU的歷史 161
7．3 CUDA架構 161
7．4 GPU程式設計模型 162
7．5 TensorFlow中GPU的設置 163
7．6 TensorFlow的GPU管理 165
7．7 GPU記憶體管理 168
7．8 在多GPU系統上分配單個GPU 168
7．9 使用多個GPU 170
7．10 小結 171

第8章 TensorFlow高 級程式設計 172
8．1 Keras簡介 172
8．2 構建深度學習模型 174
8．3 影評的情感分類 175
8．4 添加一個卷積層 179
8．5 Pretty Tensor 181
8．6 數字分類器 182
8．7 TFLearn 187
8．8 泰坦尼克號倖存者預測器 188
8．9 小結 191

第9章 TensorFlow高級多媒體程式設計 193
9．1 多媒體分析簡介 193
9．2 基於深度學習的大型對象檢測 193
9．2．1 瓶頸層 195
9．2．2 使用重訓練的模型 195
9．3 加速線性代數 197
9．3．1 TensorFlow的核心優勢 197
9．3．2 加速線性代數的準時編譯 197
9．4 TensorFlow和Keras 202
9．4．1 Keras簡介 202
9．4．2 擁有Keras的好處 203
9．4．3 視頻問答系統 203
9．5 Android上的深度學習 209
9．5．1 TensorFlow演示程式 209
9．5．2 Android入門 211
9．6 小結 214

10章 強化學習 215
10．1 強化學習基本概念 216
10．2 Q-learning演算法 217
10．3 OpenAI Gym框架簡介 218
10．4 FrozenLake-v0實現問題 220
10．5 使用TensorFlow實現Q-learning 223
10．6 小結 227
```
