
>* scikit-learn机器学习-常用算法原理及编程实战
>* http://www.hzcourse.com/web/refbook/detail/7641/226


```
第1章  機器學習介紹1

1.1  什麼是機器學習1

1.2  機器學習有什麼用2

1.3  機器學習的分類3

1.4  機器學習應用開發的典型步驟4

1.4.1  資料獲取和標記4

1.4.2  數據清洗5

1.4.3  特徵選擇5

1.4.4  模型選擇5

1.4.5  模型訓練和測試5

1.4.6  模型性能評估和優化5

1.4.7  模型使用6

1.5  複習題6

第2章  Python機器學習套裝軟體7

2.1  開發環境搭建7

2.2  IPython簡介8

2.2.1  IPython基礎8

2.2.2  IPython圖形介面13

2.3  Numpy簡介15

2.3.1  Numpy陣列15

2.3.2  Numpy運算19

2.4  Pandas簡介32

2.4.1  基本資料結構32

2.4.2  數據排序34

2.4.3  資料訪問34

2.4.4  時間序列36

2.4.5  數據視覺化36

2.4.6  文件讀寫38

2.5  Matplotlib簡介38

2.5.1  圖形樣式38

2.5.2  圖形物件40

2.5.3  畫圖操作46

2.6  scikit-learn簡介51

2.6.1  scikit-learn示例51

2.6.2  scikit-learn一般性原理和通用規則55

2.7  複習題56

2.8  拓展學習資源57

第3章  機器學習理論基礎58

3.1  過擬合和欠擬合58

3.2  成本函數59

3.3  模型準確性60

3.3.1  模型性能的不同表述方式61

3.3.2  交叉驗證資料集61

3.4  學習曲線62

3.4.1  實例：畫出學習曲線62

3.4.2  過擬合和欠擬合的特徵65

3.5  演算法模型性能優化65

3.6  查準率和召回率66

3.7  F1 Score67

3.8  複習題67

第4章  k-近鄰演算法69

4.1  演算法原理69

4.1.1  演算法優缺點69

4.1.2  演算法參數70

4.1.3  演算法的變種70

4.2  示例：使用k-近鄰演算法進行分類70

4.3  示例：使用k-近鄰演算法進行回歸擬合72

4.4  實例：糖尿病預測74

4.4.1  載入數據74

4.4.2  模型比較75

4.4.3  模型訓練及分析77

4.4.4  特徵選擇及資料視覺化78

4.5  拓展閱讀80

4.5.1  如何提高k-近鄰演算法的運算效率80

4.5.2  相關性測試80

4.6  複習題81

第5章  線性回歸演算法83

5.1  演算法原理83

5.1.1  預測函數83

5.1.2  成本函數84

5.1.3  梯度下降演算法84

5.2  多變數線性回歸演算法86

5.2.1  預測函數86

5.2.2  成本函數87

5.2.3  梯度下降演算法88

5.3  模型優化89

5.3.1  多項式與線性回歸89

5.3.2  數據歸一化89

5.4  示例：使用線性回歸演算法擬合正弦函數90

5.5  示例：測算房價92

5.5.1  輸入特徵92

5.5.2  模型訓練93

5.5.3  模型優化94

5.5.4  學習曲線95

5.6  拓展閱讀96

5.6.1  梯度下降反覆運算公式推導96

5.6.2  隨機梯度下降演算法96

5.6.3  標準方程97

5.7  複習題97

第6章  邏輯回歸演算法98

6.1  演算法原理98

6.1.1  預測函數98

6.1.2  判定邊界99

6.1.3  成本函數100

6.1.4  梯度下降演算法102

6.2  多元分類102

6.3  正則化103

6.3.1  線性回歸模型正則化103

6.3.2  邏輯回歸模型正則化104

6.4  演算法參數104

6.5  實例：乳腺癌檢測106

6.5.1  資料獲取及特徵提取106

6.5.2  模型訓練108

6.5.3  模型優化110

6.5.4  學習曲線111

6.6  拓展閱讀113

6.7  複習題114

第7章  決策樹115

7.1  演算法原理115

7.1.1  信息增益116

7.1.2  決策樹的創建119

7.1.3  剪枝演算法120

7.2  演算法參數121

7.3  實例：預測泰坦尼克號倖存者122

7.3.1  資料分析122

7.3.2  模型訓練123

7.3.3  優化模型參數124

7.3.4  模型參數選擇工具包127

7.4  拓展閱讀130

7.4.1  熵和條件熵130

7.4.2  決策樹的構建演算法130

7.5  集合演算法131

7.5.1  自助聚合演算法Bagging131

7.5.2  正向激勵演算法boosting131

7.5.3  隨機森林132

7.5.4  ExtraTrees演算法133



第8章  支持向量機134

8.1  演算法原理134
8.1.1  大間距分類演算法134
8.1.2  鬆弛係數136

8.2  核函數138
8.2.1  最簡單的核函數138
8.2.2  相似性函數140
8.2.3  常用的核函數141
8.2.4  核函數的對比142

8.3  scikit-learn裡的SVM144

8.4  實例：乳腺癌檢測146



第9章  樸素貝葉斯演算法151

9.1  演算法原理151
9.1.1  貝葉斯定理151
9.1.2  樸素貝葉斯分類法152
9.2  一個簡單的例子153

9.3  概率分佈154
9.3.1  概率統計的基本概念154
9.3.2  多項式分佈155
9.3.3  高斯分佈158

9.4  連續值的處理159

9.5  實例：文檔分類160
9.5.1  獲取資料集160
9.5.2  文檔的數學表達161
9.5.3  模型訓練163
9.5.4  模型評價165


第10章  PCA演算法168

10.1  演算法原理168
10.1.1  數據歸一化和縮放169
10.1.2  計算協方差矩陣的特徵向量169
10.1.3  資料降維和恢復170

10.2  PCA 演算法示例171
10.2.1  使用Numpy模擬PCA計算過程171
10.2.2  使用sklearn進行PCA降維運算173
10.2.3  PCA的物理含義174

10.3  PCA 的資料還原率及應用175
10.3.1  資料還原率175
10.3.2  加快監督機器學習演算法的運算速度176

10.4  實例：人臉識別176
10.4.1  載入資料集176
10.4.2  一次失敗的嘗試179
10.4.3  使用PCA來處理資料集182
10.4.4  最終結果185


第11章  k-均值演算法190

11.1  演算法原理190
11.1.1  k-均值演算法成本函數191
11.1.2  隨機初始化聚類中心點191
11.1.3  選擇聚類的個數192

11.2  scikit-learn裡的k-均值演算法192

11.3  使用k-均值對文檔進行聚類分析195
11.3.1  準備資料集195
11.3.2  載入資料集196
11.3.3  文本聚類分析197

11.4  聚類演算法性能評估200
11.4.1  Adjust Rand Index200
11.4.2  齊次性和完整性201
11.4.3  輪廓係數203



```
